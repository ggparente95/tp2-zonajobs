{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de evaluación\n",
    "def RMSLE(actual, pred):\n",
    "    actualLog = np.log(actual + 1)\n",
    "    predLog = np.log(pred + 1)\n",
    "    return (np.mean((actualLog - predLog) ** 2)) **.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usaran los sets normalizados bajo columnas SOLAMENTE.\n",
    "train = pd.read_csv('../normalized2_train.csv')\n",
    "test = pd.read_csv('../normalized2_test.csv')\n",
    "\n",
    "# Casteamos todo a int, esto es porque XgBoost dio problemas usando el set de datos con los datos heredados.\n",
    "const = ['antiguedad', 'banos', 'garages', 'metroscubiertos', 'metrostotales', 'metros']\n",
    "every_column_except_y= [col for col in train.columns if col not in ['preciomt2', 'precio','id', 'logpreciomt2', 'fecha', 'descripcion', 'titulo', 'logprecio']]\n",
    "columns = [col for col in train[every_column_except_y].columns if col not in const]\n",
    "# columns\n",
    "train.loc[:, columns] = train[columns].fillna(0)\n",
    "for column in columns:\n",
    "    train[column] = train[column].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el modelo y un set de test para tener alguna metrica\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 10, reg_alpha = 1.2, n_estimators = 600, reg_lambda = 1.4, subsample=0.8, seed=30)\n",
    "every_column_except_y= [col for col in train.columns if col not in ['preciomt2', 'precio','id', 'logpreciomt2', 'fecha', 'descripcion', 'titulo', 'logprecio']]\n",
    "\n",
    "X, y = train.loc[:,every_column_except_y], train['logprecio']\n",
    "#Entrenamos con el dataset entero\n",
    "xg_reg.fit(train[every_column_except_y], train['logpreciomt2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecimos y guardamos\n",
    "pred = xg_reg.predict(test[every_column_except_y])\n",
    "final = test[['id']]\n",
    "final.loc[:, 'target'] = test.metros * np.expm1(pred)\n",
    "final.set_index('id').to_csv('../prediction_xgboostTomTHT3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
