{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import OrderedDict\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../normalized_train.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "test = pd.read_csv('../normalized_test.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "train_raw = pd.read_csv('../train.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "                'tipodepropiedad': 'category',\n",
    "                'provincia': 'category',\n",
    "                'ciudad': 'category',\n",
    "\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "test = test.set_index('id').dropna(subset=['titulo'])\n",
    "train = train.set_index('id').dropna(subset=['titulo'])\n",
    "df_all = train.append(test)\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apartamento',\n",
       " 'bodega comercial',\n",
       " 'casa',\n",
       " 'casa en condominio',\n",
       " 'casa uso de suelo',\n",
       " 'departamento compartido',\n",
       " 'duplex',\n",
       " 'edificio',\n",
       " 'huerta',\n",
       " 'inmuebles productivos urbanos',\n",
       " 'local comercial',\n",
       " 'local en centro comercial',\n",
       " 'lote',\n",
       " 'nave industrial',\n",
       " 'oficina comercial',\n",
       " 'otros',\n",
       " 'quinta vacacional',\n",
       " 'rancho',\n",
       " 'terreno',\n",
       " 'terreno comercial',\n",
       " 'terreno industrial',\n",
       " 'villa',\n",
       " 'hospedaje',\n",
       " 'garage']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipodepopiedades = [item.lower() for item in train_raw.tipodepropiedad.cat.categories]\n",
    "tipodepopiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('venta', 132690),\n",
       " ('departamento', 47720),\n",
       " ('san', 20543),\n",
       " ('excelente', 15632),\n",
       " ('lomas', 13890),\n",
       " ('col', 13448),\n",
       " ('residencial', 12570),\n",
       " ('hermosa', 11738),\n",
       " ('condominio', 10751),\n",
       " ('valle', 9904),\n",
       " ('recamaras', 8851),\n",
       " ('oportunidad', 8725),\n",
       " ('santa', 8598),\n",
       " ('fracc', 8115),\n",
       " ('fraccionamiento', 7559),\n",
       " ('nueva', 7399),\n",
       " ('casas', 7364),\n",
       " ('remate', 7127),\n",
       " ('bonita', 6797),\n",
       " ('cerca', 6441)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#nltk.download('stopwords')\n",
    "stopwords = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "a,b = 'áéíóúü','aeiouu'\n",
    "trans = str.maketrans(a,b)\n",
    "\n",
    "def countplease(x):\n",
    "    \n",
    "#     print(x)\n",
    "    if(x!=x): return;\n",
    "    \n",
    "    x = tokenizer.tokenize(x)\n",
    "\n",
    "    for word in list(x):  # iterating on a copy since removing will mess things up\n",
    "        if word in stopwords or word.isnumeric() or word in tipodepopiedades:\n",
    "            x.remove(word)\n",
    "\n",
    "    x = [item.translate(trans) for item in x]\n",
    "    counter.update(x)\n",
    "    \n",
    "\n",
    "df_all['titulo'].apply(lambda x: countplease(x))\n",
    "counter.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soloprecio = train[['logprecio', 'metros']]\n",
    "solopreciotrain = soloprecio;\n",
    "solotest = test[['metros']]\n",
    "def buildDataframe(appearences, counter):\n",
    "    newDict = dict()\n",
    "    # Iterate over all the items in dictionary and filter items which has even keys\n",
    "    for (key, value) in dict(counter).items():\n",
    "        # Check if key is even then add pair to new dictionary\n",
    "    #     print(value)\n",
    "        if int(value) > appearences:\n",
    "            newDict[key] = value\n",
    "\n",
    "    # print('Filtered Dictionary : ')\n",
    "    print(len(newDict.keys()))\n",
    "    columns = list(newDict.keys())\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        soloprecio[column] = train['titulo'].str.contains(column)\n",
    "        solotest[column] = test['titulo'].str.contains(column)\n",
    "    #     columncontent = []\n",
    "    return int(len(newDict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(10), activation='tanh', solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "columns = []\n",
    "def rmse_cv(model, appearence):\n",
    "    columns.append(buildDataframe(appearence, counter))\n",
    "\n",
    "    \n",
    "    every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "    print(solopreciotrain.logprecio.isnull().sum())\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 2))\n",
    "    return(rmse)\n",
    "\n",
    "def xgBoost_rmse(model, appearence):\n",
    "    columns.append(buildDataframe(appearence, counter))\n",
    "    \n",
    "    every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "    print(solopreciotrain.logprecio.isnull().sum())\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n",
    "    print(OrderedDict(sorted(model.get_booster().get_fscore().items(), key=lambda t: t[1], reverse=True)))\n",
    "    return (OrderedDict(sorted(model.get_booster().get_fscore().items(), key=lambda t: t[1], reverse=True)))\n",
    "#     return(rmse)\n",
    "\n",
    "appearences = list(range(2000, 0, -200))\n",
    "# cv_neuron = [rmse_cv(clf, appearence).mean() for appearence in appearences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:26:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.48765667857212114\n",
      "OrderedDict([('metros', 4700), ('venta', 410), ('departamento', 328), ('d', 271), ('c', 266), ('depa', 259), ('m', 235), ('col', 205), ('san', 204), ('l', 198), ('b', 198), ('i', 190), ('f', 168), ('valle', 167), ('excelente', 154), ('n', 138), ('depto', 129), ('av', 127), ('centro', 118), ('sta', 116), ('residencial', 112), ('condominio', 111), ('local', 111), ('fracc', 108), ('comercial', 107), ('m2', 105), ('lomas', 101), ('fe', 101), ('pre', 96), ('min', 91), ('hermosa', 90), ('rec', 88), ('santa', 84), ('loma', 83), ('zona', 82), ('remate', 80), ('residencia', 80), ('real', 80), ('rio', 78), ('sur', 78), ('cerca', 77), ('casas', 77), ('departamentos', 76), ('bodega', 73), ('calle', 73), ('nuevo', 71), ('vista', 71), ('ciudad', 70), ('oportunidad', 69), ('colonia', 69), ('mar', 68), ('sol', 66), ('juriquilla', 65), ('gran', 65), ('quinta', 60), ('oficina', 59), ('nueva', 58), ('plaza', 57), ('monte', 57), ('recamaras', 56), ('vendo', 56), ('dos', 56), ('unidad', 55), ('bosque', 54), ('torre', 54), ('mts', 53), ('norte', 52), ('privada', 52), ('pedregal', 52), ('polanco', 51), ('nivel', 50), ('playa', 49), ('juan', 49), ('parque', 49), ('cuadra', 48), ('fraccionamiento', 48), ('hacienda', 48), ('miguel', 48), ('morelos', 47), ('terrenos', 46), ('sola', 46), ('vende', 46), ('lago', 46), ('jardines', 46), ('hermoso', 45), ('tec', 45), ('bonito', 45), ('renta', 45), ('campestre', 45), ('preventa', 42), ('tlalpan', 42), ('pedro', 42), ('amplia', 42), ('francisco', 42), ('edo', 41), ('esquina', 41), ('paseo', 40), ('carretera', 40), ('lujo', 39), ('amplio', 39), ('zapopan', 39), ('super', 39), ('benito', 37), ('tipo', 37), ('guadalupe', 37), ('planta', 36), ('condesa', 35), ('house', 35), ('bonita', 35), ('inversion', 35), ('propiedad', 35), ('ubicado', 35), ('angel', 34), ('ii', 34), ('cd', 34), ('palmas', 34), ('piso', 34), ('frente', 34), ('bosques', 34), ('hidalgo', 34), ('puerto', 34), ('precioso', 33), ('ubicacion', 33), ('ideal', 32), ('villas', 32), ('terraza', 31), ('coto', 31), ('jardin', 31), ('cumbres', 31), ('ph', 30), ('acapulco', 30), ('clave', 30), ('reforma', 30), ('chapultepec', 30), ('alberca', 30), ('campo', 30), ('cholul', 29), ('desarrollo', 29), ('central', 29), ('puerta', 29), ('secc', 29), ('torres', 29), ('precio', 29), ('tlalnepantla', 29), ('izcalli', 29), ('toluca', 29), ('uso', 29), ('locales', 28), ('cuernavaca', 28), ('mex', 28), ('jalisco', 28), ('colinas', 28), ('pesos', 27), ('buen', 27), ('estrena', 27), ('poniente', 26), ('atizapan', 25), ('bancario', 25), ('puebla', 25), ('iztapalapa', 25), ('mejor', 25), ('tlajomulco', 25), ('metepec', 25), ('roma', 24), ('remodelada', 24), ('preciosa', 24), ('tequisquiapan', 24), ('buena', 24), ('minutos', 24), ('punta', 24), ('industrial', 24), ('remato', 23), ('juarez', 23), ('privado', 23), ('habitacion', 23), ('fuentes', 23), ('avenida', 23), ('tecamac', 22), ('solo', 22), ('carmen', 22), ('golf', 22), ('jose', 22), ('monterrey', 22), ('leon', 22), ('cholula', 21), ('grande', 21), ('coyoacan', 21), ('club', 21), ('bancaria', 21), ('cuajimalpa', 21), ('santiago', 21), ('linda', 21), ('cancun', 21), ('pinos', 20), ('huixquilucan', 20), ('baños', 20), ('isidro', 20), ('estilo', 20), ('remodelado', 20), ('rincon', 20), ('seguridad', 20), ('lista', 20), ('queretaro', 20), ('cruz', 20), ('maria', 20), ('hipotecario', 19), ('mirador', 19), ('infonavit', 19), ('mexico', 19), ('narvarte', 19), ('alvaro', 19), ('merida', 19), ('garza', 19), ('exclusivo', 19), ('cerrada', 19), ('tres', 19), ('conjunto', 19), ('habitacional', 19), ('distrito', 18), ('portales', 18), ('vigilancia', 18), ('azcapotzalco', 18), ('baja', 18), ('paseos', 18), ('chihuahua', 17), ('horizontal', 17), ('oriente', 17), ('dentro', 17), ('cuauhtemoc', 17), ('naucalpan', 17), ('pueblo', 17), ('periferico', 17), ('verdes', 17), ('country', 17), ('verde', 17), ('excelentes', 17), ('xochimilco', 17), ('universidad', 17), ('zaragoza', 17), ('herradura', 16), ('interlomas', 16), ('oficinas', 16), ('ecatepec', 16), ('suelo', 16), ('insurgentes', 16), ('estrene', 16), ('credito', 16), ('sierra', 16), ('madero', 16), ('remodelar', 16), ('veracruz', 16), ('boca', 16), ('inversionistas', 16), ('sector', 16), ('mateo', 16), ('lopez', 16), ('baño', 16), ('coacalco', 15), ('antonio', 15), ('hermosillo', 15), ('entrega', 15), ('exclusiva', 15), ('construccion', 15), ('satelite', 15), ('pachuca', 15), ('luis', 15), ('inmediata', 15), ('modelo', 15), ('recuperacion', 15), ('vallarta', 15), ('dorada', 15), ('yucatan', 15), ('nicolas', 15), ('magnifica', 15), ('niveles', 15), ('estrenar', 14), ('jeronimo', 14), ('providencia', 14), ('espectacular', 14), ('coapa', 14), ('aguilas', 14), ('increible', 14), ('lindavista', 14), ('cerrado', 13), ('mision', 13), ('nacional', 13), ('blanca', 13), ('barrio', 13), ('cuadras', 13), ('guadalajara', 13), ('garden', 12), ('esmeralda', 12), ('anahuac', 12), ('cuautitlan', 12), ('habitaciones', 12), ('alamos', 12), ('totalmente', 12), ('camino', 12), ('roof', 11), ('apodaca', 11), ('morelia', 11), ('cima', 11), ('tampico', 11), ('garcia', 11), ('diamante', 11), ('condiciones', 11), ('bugambilias', 11), ('arboledas', 11), ('obregon', 10), ('saltillo', 10), ('proyecto', 10), ('plantas', 10), ('gustavo', 10), ('penthouse', 10), ('bien', 10), ('dorado', 10), ('rinconada', 10), ('nuevos', 10), ('centrica', 9), ('federal', 9), ('milenio', 9), ('balcones', 9), ('ubicada', 9), ('moderna', 9), ('espacios', 9), ('corregidora', 9), ('refugio', 9), ('anita', 9), ('acabados', 9), ('jesus', 9), ('iii', 9), ('aragon', 8), ('napoles', 8), ('tultitlan', 8), ('magdalena', 8), ('moderno', 8), ('amplios', 8), ('equipada', 7), ('seccion', 7), ('recien', 7), ('azul', 7), ('angelopolis', 6), ('torreon', 6), ('quintas', 6), ('heroes', 6), ('ampliacion', 6), ('bellavista', 5), ('andres', 5), ('nuevas', 4), ('americas', 3), ('potosi', 3), ('creditos', 3), ('parques', 3), ('minimalista', 2)])\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(learning_rate =0.3, n_estimators=700, max_depth=5, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6, scale_pos_weight=1, seed=27)\n",
    "important_words = xgBoost_rmse(model, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clffinal = MLPRegressor(activation='tanh', solver='adam')\n",
    "# buildDataframe(15000)\n",
    "# every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_neuron = pd.Series(cv_neuron, index = columns)\n",
    "# cv_neuron.plot(title = \"Estimación solo con palabras del titulo\")\n",
    "# plt.xlabel(\"Columnas\")\n",
    "# plt.ylabel(\"rmse\")\n",
    "# cv_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "# np.sqrt(mean_squared_error(y_test, clf.predict(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clffinal = MLPRegressor(activation='tanh', solver='adam')\n",
    "#buildDataframe(15000)\n",
    "every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clffinal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sqrt(mean_squared_error(y_test, clffinal.predict(X_test)))\n",
    "len(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildDataframe(20, Counter(important_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fh1</th>\n",
       "      <th>fh2</th>\n",
       "      <th>fh3</th>\n",
       "      <th>fh4</th>\n",
       "      <th>fh5</th>\n",
       "      <th>fh6</th>\n",
       "      <th>fh7</th>\n",
       "      <th>fh8</th>\n",
       "      <th>fh9</th>\n",
       "      <th>fh10</th>\n",
       "      <th>...</th>\n",
       "      <th>fh21</th>\n",
       "      <th>fh22</th>\n",
       "      <th>fh23</th>\n",
       "      <th>fh24</th>\n",
       "      <th>fh25</th>\n",
       "      <th>fh26</th>\n",
       "      <th>fh27</th>\n",
       "      <th>fh28</th>\n",
       "      <th>fh29</th>\n",
       "      <th>fh30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58622 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fh1  fh2  fh3  fh4  fh5  fh6  fh7  fh8  fh9  fh10  ...  fh21  fh22  \\\n",
       "id                                                         ...               \n",
       "4941    0.0 -1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.0  ...   0.0  -1.0   \n",
       "51775   0.0 -1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "115253  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0  ...   0.0  -1.0   \n",
       "299321  0.0 -1.0  1.0  0.0  0.0 -1.0  0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "173570  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  -2.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "75094   0.0  0.0  1.0  0.0 -1.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  -1.0   \n",
       "171847  0.0  0.0  1.0  0.0 -1.0  0.0  0.0  0.0  1.0   0.0  ...   0.0  -1.0   \n",
       "138313  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  -1.0   \n",
       "271268  0.0 -1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  -2.0   \n",
       "72612   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  -1.0   \n",
       "\n",
       "        fh23  fh24  fh25  fh26  fh27  fh28  fh29  fh30  \n",
       "id                                                      \n",
       "4941    -1.0   1.0  -1.0   0.0   0.0   0.0   0.0   1.0  \n",
       "51775    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "115253   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "299321   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "173570   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "75094    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "171847   0.0   1.0  -1.0   0.0   0.0   0.0   0.0   0.0  \n",
       "138313   0.0   0.0  -1.0   1.0   0.0   0.0   0.0  -1.0  \n",
       "271268   0.0   0.0  -1.0   0.0   0.0   0.0  -1.0   0.0  \n",
       "72612    0.0   1.0  -1.0   0.0   0.0   0.0   0.0   1.0  \n",
       "\n",
       "[58622 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "cantidad_features = 30\n",
    "\n",
    "h = FeatureHasher(n_features=cantidad_features, input_type='string')\n",
    "every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio', 'metros']]\n",
    "\n",
    "train_hashtrick = solopreciotrain.copy()\n",
    "test_hashtrick = solotest.copy()\n",
    "\n",
    "# Recorro las columnas y asigno la palabra si es True, sino nan.\n",
    "for el in every_column_except_y:\n",
    "    train_hashtrick.loc[train_hashtrick[el] == True, el] = el\n",
    "    train_hashtrick.loc[train_hashtrick[el] == False, el] = np.nan\n",
    "    test_hashtrick.loc[test_hashtrick[el] == True, el] = el\n",
    "    test_hashtrick.loc[test_hashtrick[el] == False, el] = np.nan\n",
    "\n",
    "# Armo la matriz de arrays para poder usar the hashing trick\n",
    "train_hashtrick = train_hashtrick[every_column_except_y].apply(lambda x: list(filter(lambda y : y == y, x)), axis=1)\n",
    "test_hashtrick = test_hashtrick[every_column_except_y].apply(lambda x: list(filter(lambda y : y == y, x)), axis=1)\n",
    "\n",
    "# Termino de armar los arrays.\n",
    "names = [f'fh{el + 1}' for el in range(cantidad_features)]\n",
    "f = h.transform(train_hashtrick.values)\n",
    "train_hashtrick = pd.DataFrame(f.toarray(), columns=names)\n",
    "train_hashtrick['id'] = train.index\n",
    "train_hashtrick = train_hashtrick.set_index('id')\n",
    "f = h.transform(test_hashtrick.values)\n",
    "test_hashtrick = pd.DataFrame(f.toarray(), columns=names)\n",
    "test_hashtrick['id'] = test.index\n",
    "test_hashtrick = test_hashtrick.set_index('id')\n",
    "test_hashtrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hashtrick.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltest = pd.read_csv('../normalized_test.csv')\n",
    "finaltest = finaltest.set_index('id')\n",
    "\n",
    "\n",
    "test_raw = pd.read_csv('../test.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "                'tipodepropiedad': 'category',\n",
    "                'provincia': 'category',\n",
    "                'ciudad': 'category',\n",
    "\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "idzonatest = test_raw.set_index('id')['idzona']\n",
    "finaltest = finaltest.join(idzonatest, how='left')\n",
    "finaltest = finaltest.join(test_hashtrick, how='left')\n",
    "finaltest.loc[:, 'fecha'] = pd.to_datetime(finaltest.fecha).values.astype(np.int64)\n",
    "finaltest.loc[:, names] = finaltest[names].fillna(0)\n",
    "finaltest.to_csv('../normalized2_test.csv')\n",
    "# finaltest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain = pd.read_csv('../normalized_train.csv')\n",
    "finaltrain = finaltrain.set_index('id')\n",
    "\n",
    "idzonatest = train_raw.set_index('id')['idzona']\n",
    "finaltrain = finaltrain.join(idzonatest, how='left')\n",
    "finaltrain.loc[:, 'fecha'] = pd.to_datetime(finaltrain.fecha).values.astype(np.int64)\n",
    "finaltrain = finaltrain.join(train_hashtrick)\n",
    "\n",
    "finaltrain.loc[:, names] = finaltrain[names].fillna(0)\n",
    "finaltrain.to_csv('../normalized2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# finaltrain.fecha.asType().values.astype(np.int64) // 10 ** 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "254099    1440288000000000000\n",
       "53461     1372377600000000000\n",
       "247984    1445040000000000000\n",
       "209067    1331251200000000000\n",
       "185997    1465257600000000000\n",
       "                 ...         \n",
       "119879    1423353600000000000\n",
       "259178    1404950400000000000\n",
       "131932    1425340800000000000\n",
       "146867    1419552000000000000\n",
       "121958    1434672000000000000\n",
       "Name: fecha, Length: 239907, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltrain.fecha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
