{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import OrderedDict\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230872, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../normalized_train.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "test = pd.read_csv('../normalized_test.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "train_raw = pd.read_csv('../train.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "                'tipodepropiedad': 'category',\n",
    "                'provincia': 'category',\n",
    "                'ciudad': 'category'\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "test = test.set_index('id').dropna(subset=['titulo'])\n",
    "train = train.set_index('id').dropna(subset=['titulo'])\n",
    "df_all = train.append(test)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apartamento',\n",
       " 'bodega comercial',\n",
       " 'casa',\n",
       " 'casa en condominio',\n",
       " 'casa uso de suelo',\n",
       " 'departamento compartido',\n",
       " 'duplex',\n",
       " 'edificio',\n",
       " 'huerta',\n",
       " 'inmuebles productivos urbanos',\n",
       " 'local comercial',\n",
       " 'local en centro comercial',\n",
       " 'lote',\n",
       " 'nave industrial',\n",
       " 'oficina comercial',\n",
       " 'otros',\n",
       " 'quinta vacacional',\n",
       " 'rancho',\n",
       " 'terreno',\n",
       " 'terreno comercial',\n",
       " 'terreno industrial',\n",
       " 'villa',\n",
       " 'hospedaje',\n",
       " 'garage']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipodepopiedades = [item.lower() for item in train_raw.tipodepropiedad.cat.categories]\n",
    "tipodepopiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('venta', 131068),\n",
       " ('departamento', 47327),\n",
       " ('san', 20304),\n",
       " ('excelente', 15410),\n",
       " ('lomas', 13817),\n",
       " ('col', 13270),\n",
       " ('residencial', 12433),\n",
       " ('hermosa', 11714),\n",
       " ('condominio', 10737),\n",
       " ('valle', 9846),\n",
       " ('recamaras', 8825),\n",
       " ('oportunidad', 8598),\n",
       " ('santa', 8511),\n",
       " ('fracc', 8037),\n",
       " ('fraccionamiento', 7495),\n",
       " ('nueva', 7384),\n",
       " ('casas', 7347),\n",
       " ('remate', 7086),\n",
       " ('bonita', 6782),\n",
       " ('cerca', 6379)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "stopwords = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "a,b = 'áéíóúü','aeiouu'\n",
    "trans = str.maketrans(a,b)\n",
    "\n",
    "def countplease(x):\n",
    "    \n",
    "#     print(x)\n",
    "    if(x!=x): return;\n",
    "    \n",
    "    x = tokenizer.tokenize(x)\n",
    "\n",
    "    for word in list(x):  # iterating on a copy since removing will mess things up\n",
    "        if word in stopwords or word.isnumeric() or word in tipodepopiedades:\n",
    "            x.remove(word)\n",
    "\n",
    "    x = [item.translate(trans) for item in x]\n",
    "    counter.update(x)\n",
    "    \n",
    "\n",
    "df_all['titulo'].apply(lambda x: countplease(x))\n",
    "counter.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soloprecio = train[['logprecio', 'metros']]\n",
    "solopreciotrain = soloprecio;\n",
    "solotest = test[['metros']]\n",
    "def buildDataframe(appearences, counter):\n",
    "    newDict = dict()\n",
    "    # Iterate over all the items in dictionary and filter items which has even keys\n",
    "    for (key, value) in dict(counter).items():\n",
    "        # Check if key is even then add pair to new dictionary\n",
    "    #     print(value)\n",
    "        if int(value) > appearences:\n",
    "            newDict[key] = value\n",
    "\n",
    "    # print('Filtered Dictionary : ')\n",
    "    print(len(newDict.keys()))\n",
    "    columns = list(newDict.keys())\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        soloprecio[column] = train['titulo'].str.contains(column)\n",
    "        solotest[column] = test['titulo'].str.contains(column)\n",
    "    #     columncontent = []\n",
    "    return int(len(newDict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(10), activation='tanh', solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "columns = []\n",
    "def rmse_cv(model, appearence):\n",
    "    columns.append(buildDataframe(appearence, counter))\n",
    "\n",
    "    \n",
    "    every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "    print(solopreciotrain.logprecio.isnull().sum())\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 2))\n",
    "    return(rmse)\n",
    "\n",
    "def xgBoost_rmse(model, appearence):\n",
    "    columns.append(buildDataframe(appearence, counter))\n",
    "    \n",
    "    every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "    print(solopreciotrain.logprecio.isnull().sum())\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n",
    "    print(OrderedDict(sorted(model.get_booster().get_fscore().items(), key=lambda t: t[1], reverse=True)))\n",
    "    return (OrderedDict(sorted(model.get_booster().get_fscore().items(), key=lambda t: t[1], reverse=True)))\n",
    "#     return(rmse)\n",
    "\n",
    "appearences = list(range(2000, 0, -200))\n",
    "# cv_neuron = [rmse_cv(clf, appearence).mean() for appearence in appearences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:37:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.49543795910048527\n",
      "OrderedDict([('metros', 4175), ('departamento', 810), ('venta', 512), ('d', 281), ('c', 272), ('san', 247), ('depto', 246), ('col', 236), ('i', 210), ('av', 192), ('valle', 175), ('remate', 168), ('l', 165), ('fracc', 161), ('fe', 158), ('m2', 152), ('lomas', 150), ('excelente', 148), ('condominio', 142), ('residencial', 140), ('rio', 134), ('n', 132), ('hermosa', 126), ('local', 125), ('pre', 123), ('min', 121), ('rec', 121), ('centro', 112), ('loma', 111), ('mar', 110), ('norte', 107), ('real', 105), ('torre', 104), ('departamentos', 102), ('santa', 101), ('comercial', 99), ('nuevo', 98), ('cerca', 97), ('gran', 95), ('zona', 94), ('casas', 93), ('residencia', 90), ('ciudad', 89), ('bosque', 86), ('oportunidad', 84), ('juriquilla', 78), ('vista', 78), ('pedregal', 78), ('oficina', 77), ('nueva', 76), ('sol', 75), ('vendo', 72), ('sola', 71), ('calle', 70), ('sur', 69), ('planta', 66), ('privada', 65), ('quinta', 64), ('monte', 62), ('unidad', 62), ('miguel', 61), ('jardines', 61), ('pesos', 59), ('paseo', 58), ('polanco', 57), ('plaza', 57), ('amplio', 56), ('lago', 56), ('colonia', 56), ('zapopan', 56), ('parque', 55), ('dos', 55), ('esquina', 54), ('recamaras', 53), ('preventa', 52), ('bonita', 52), ('alberca', 52), ('fraccionamiento', 52), ('playa', 51), ('hermoso', 51), ('terrenos', 50), ('house', 50), ('buena', 50), ('pedro', 50), ('puerta', 50), ('frente', 50), ('jardin', 50), ('infonavit', 49), ('hacienda', 49), ('lujo', 49), ('vende', 49), ('bodega', 48), ('super', 48), ('amplia', 48), ('cumbres', 48), ('condesa', 47), ('interlomas', 47), ('roma', 47), ('ii', 47), ('angel', 47), ('renta', 47), ('benito', 46), ('tipo', 46), ('precio', 46), ('bancario', 45), ('verdes', 44), ('bosques', 44), ('puerto', 43), ('edo', 43), ('coto', 43), ('reforma', 43), ('club', 42), ('narvarte', 42), ('tlalpan', 42), ('nivel', 42), ('campestre', 41), ('preciosa', 41), ('morelos', 41), ('huixquilucan', 40), ('naucalpan', 40), ('villas', 39), ('cuajimalpa', 39), ('minutos', 38), ('linda', 38), ('uso', 38), ('hidalgo', 37), ('piso', 37), ('tlalnepantla', 37), ('herradura', 36), ('chapultepec', 36), ('cuernavaca', 36), ('distrito', 36), ('inversion', 36), ('francisco', 36), ('cd', 36), ('bancaria', 35), ('portales', 35), ('remato', 35), ('juan', 35), ('monterrey', 35), ('ph', 34), ('precioso', 34), ('solo', 33), ('mexico', 33), ('coyoacan', 32), ('carmen', 32), ('ideal', 32), ('clave', 31), ('ubicacion', 31), ('estilo', 31), ('habitaciones', 31), ('estrena', 30), ('chihuahua', 30), ('paseos', 30), ('toluca', 30), ('baja', 29), ('aguilas', 29), ('oficinas', 29), ('alvaro', 29), ('cancun', 29), ('ubicado', 29), ('estrene', 29), ('country', 29), ('fuentes', 29), ('credito', 28), ('jeronimo', 28), ('exclusivo', 28), ('privado', 28), ('puebla', 28), ('poniente', 28), ('baños', 27), ('mejor', 27), ('cuauhtemoc', 27), ('madero', 27), ('cholula', 27), ('cerrada', 27), ('luis', 27), ('coacalco', 26), ('leon', 26), ('merida', 26), ('horizontal', 26), ('conjunto', 26), ('insurgentes', 26), ('juarez', 26), ('locales', 26), ('cruz', 26), ('remodelar', 26), ('golf', 26), ('colinas', 26), ('avenida', 26), ('palmas', 26), ('mateo', 25), ('bonito', 25), ('acapulco', 24), ('vallarta', 24), ('garza', 24), ('izcalli', 24), ('anahuac', 24), ('nacional', 24), ('espacios', 24), ('vigilancia', 23), ('satelite', 23), ('condiciones', 23), ('guadalupe', 22), ('zaragoza', 22), ('ecatepec', 22), ('metepec', 22), ('carretera', 22), ('remodelada', 22), ('azcapotzalco', 22), ('punta', 21), ('moderna', 21), ('nicolas', 21), ('garden', 21), ('sector', 21), ('esmeralda', 21), ('mision', 20), ('modelo', 20), ('iztapalapa', 20), ('pachuca', 20), ('tres', 20), ('milenio', 20), ('magnifica', 20), ('propiedad', 19), ('veracruz', 19), ('santiago', 19), ('seccion', 19), ('andres', 18), ('hipotecario', 18), ('jose', 18), ('bien', 18), ('seguridad', 18), ('queretaro', 18), ('jalisco', 17), ('heroes', 17), ('maria', 17), ('bugambilias', 17), ('atizapan', 16), ('periferico', 16), ('excelentes', 16), ('niveles', 15), ('estrenar', 15), ('iii', 15), ('tlajomulco', 14), ('acabados', 14), ('arboledas', 14), ('yucatan', 14), ('campo', 14), ('mirador', 13), ('dorado', 13), ('gustavo', 13), ('cuautitlan', 13), ('rinconada', 12), ('refugio', 12), ('roof', 11), ('ubicada', 10), ('federal', 8), ('guadalajara', 7), ('plantas', 5), ('obregon', 4), ('aragon', 3), ('americas', 3), ('angelopolis', 3), ('potosi', 3)])\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(learning_rate =0.1, n_estimators=700, max_depth=5, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6, scale_pos_weight=1, seed=27)\n",
    "important_words = xgBoost_rmse(model, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clffinal = MLPRegressor(activation='tanh', solver='adam')\n",
    "# buildDataframe(15000)\n",
    "# every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_neuron = pd.Series(cv_neuron, index = columns)\n",
    "# cv_neuron.plot(title = \"Estimación solo con palabras del titulo\")\n",
    "# plt.xlabel(\"Columnas\")\n",
    "# plt.ylabel(\"rmse\")\n",
    "# cv_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)\n",
    "# np.sqrt(mean_squared_error(y_test, clf.predict(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clffinal = MLPRegressor(activation='tanh', solver='adam')\n",
    "buildDataframe(15000)\n",
    "every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(solopreciotrain[every_column_except_y], solopreciotrain.logprecio, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clffinal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(y_test, clffinal.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildDataframe(50, Counter(important_words).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "cantidad_features = 20\n",
    "\n",
    "h = FeatureHasher(n_features=cantidad_features, input_type='string')\n",
    "every_column_except_y= [col for col in solopreciotrain.columns if col not in ['id', 'logprecio', 'metros']]\n",
    "\n",
    "train_hashtrick = solopreciotrain.copy()\n",
    "test_hashtrick = solotest.copy()\n",
    "\n",
    "# Recorro las columnas y asigno la palabra si es True, sino nan.\n",
    "for el in every_column_except_y:\n",
    "    train_hashtrick.loc[train_hashtrick[el] == True, el] = el\n",
    "    train_hashtrick.loc[train_hashtrick[el] == False, el] = np.nan\n",
    "    test_hashtrick.loc[test_hashtrick[el] == True, el] = el\n",
    "    test_hashtrick.loc[test_hashtrick[el] == False, el] = np.nan\n",
    "\n",
    "# Armo la matriz de arrays para poder usar the hashing trick\n",
    "train_hashtrick = train_hashtrick[every_column_except_y].apply(lambda x: list(filter(lambda y : y == y, x)), axis=1)\n",
    "test_hashtrick = test_hashtrick[every_column_except_y].apply(lambda x: list(filter(lambda y : y == y, x)), axis=1)\n",
    "\n",
    "# Termino de armar los arrays.\n",
    "names = [f'fh{el + 1}' for el in range(cantidad_features)]\n",
    "f = h.transform(train_hashtrick.values)\n",
    "train_hashtrick = pd.DataFrame(f.toarray(), columns=names)\n",
    "train_hashtrick['id'] = train.index\n",
    "train_hashtrick = train_hashtrick.set_index('id')\n",
    "f = h.transform(test_hashtrick.values)\n",
    "test_hashtrick = pd.DataFrame(f.toarray(), columns=names)\n",
    "test_hashtrick['id'] = test.index\n",
    "test_hashtrick = test_hashtrick.set_index('id')\n",
    "test_hashtrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hashtrick.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltest = pd.read_csv('../normalized_test.csv')\n",
    "finaltest = finaltest.set_index('id')\n",
    "finaltest = finaltest.join(test_hashtrick, how='left')\n",
    "\n",
    "finaltest.loc[:, names] = finaltest[names].fillna(0)\n",
    "finaltest.to_csv('../normalized2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain = pd.read_csv('../normalized_train.csv')\n",
    "finaltrain = finaltrain.set_index('id')\n",
    "finaltrain = finaltrain.join(train_hashtrick)\n",
    "\n",
    "finaltrain.loc[:, names] = finaltrain[names].fillna(0)\n",
    "finaltrain.to_csv('../normalized2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain.precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
