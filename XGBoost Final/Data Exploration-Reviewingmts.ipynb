{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'train.csv' does not exist: b'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-13e8008f9c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;34m'ciudad'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'category'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             },\n\u001b[0;32m---> 11\u001b[0;31m         parse_dates=['fecha'])\n\u001b[0m\u001b[1;32m     12\u001b[0m test = pd.read_csv('test.csv',\n\u001b[1;32m     13\u001b[0m         dtype={'gimnasio': int,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train.csv' does not exist: b'train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('../train.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "                'tipodepropiedad': 'category',\n",
    "                'provincia': 'category',\n",
    "                'ciudad': 'category'\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "test = pd.read_csv('test.csv',\n",
    "        dtype={'gimnasio': int,\n",
    "                'usosmultiples': int,\n",
    "                'escuelascercanas': int,\n",
    "                'piscina': int,\n",
    "                'centroscomercialescercanos': int,\n",
    "                'tipodepropiedad': 'category',\n",
    "                'provincia': 'category',\n",
    "                'ciudad': 'category'\n",
    "            },\n",
    "        parse_dates=['fecha'])\n",
    "# train = normailize_df(train, True)\n",
    "# test = normailize_df(test, False)\n",
    "train.drop(columns=[\"direccion\", \"lat\", \"lng\"], inplace=True)\n",
    "test.drop(columns=[\"direccion\", \"lat\", \"lng\"], inplace=True)\n",
    "train = train[~train.tipodepropiedad.isnull()]\n",
    "df_all = train.append(test)\n",
    "df_all['fecha'] = df.fecha.values.astype(np.int64)\n",
    "test[test.tipodepropiedad.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[:train] = np.log(df_train.SalePrice)\n",
    "df_all['preciomt2'] = df_all['precio'] / (df_all['metroscubiertos'] + df_all['metrostotales'])\n",
    "df_all['logpreciomt2'] = np.log1p(df_all.preciomt2)\n",
    "df_all['logprecio'] = np.log1p(df_all.precio)\n",
    "\n",
    "corr = df_all.corr().abs()\n",
    "corr.precio[corr.precio >= 0.5].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(df):\n",
    "    \n",
    "    sum_null = df.isnull().sum()\n",
    "    total = df.isnull().count()\n",
    "    percent_nullvalues = 100* sum_null / total \n",
    "    df_null = pd.DataFrame()\n",
    "    df_null['Total'] = total\n",
    "    df_null['Null_Count'] = sum_null\n",
    "    df_null['Percent'] = round(percent_nullvalues,2)\n",
    "    df_null = df_null.sort_values(by='Null_Count',ascending = False)\n",
    "    df_null = df_null[df_null.Null_Count > 0]\n",
    "    \n",
    "    return(df_null)\n",
    "null_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values(train[train['metrostotales'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values(train[(train['metroscubiertos'].isnull())])\n",
    "#los que no tienen metros cubiertos mayormente tampoco tienen baños declarados. Podemos asumir\n",
    "#si no hay metros cubiertos entonces --> no hay banos \n",
    "# train[train['metroscubiertos'].isnull()].tipodepropiedad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisemos cuidadosamente los terrenos primero\n",
    "null_values(train[(train['metroscubiertos'].isnull()) & (train['tipodepropiedad'] == 'Terreno')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_all[df_all['tipodepropiedad'] == 'Terreno'].corr()\n",
    "corr['precio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df_all['metroscubiertos'].isnull()) & (df_all['tipodepropiedad'] == 'Terreno')\n",
    "df_all.loc[condition, 'garages'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df_all['metroscubiertos'].isnull()) & (df_all['tipodepropiedad'] == 'Terreno Comercial')\n",
    "df_all.loc[condition, 'antiguedad'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que los que tienen valores nulos en metros cubiertos tambien tienen banos, habitaciones, garages y antiguedad. Consideramos todos estos \n",
    "# como 0 entonces.\n",
    "condition = (df_all['metroscubiertos'].isnull()) & (df_all['tipodepropiedad'] == 'Terreno')\n",
    "df_all.loc[condition, 'banos'] = 0\n",
    "df_all.loc[condition, 'habitaciones'] = 0\n",
    "df_all.loc[condition, 'metroscubiertos'] = 0\n",
    "df_all.loc[condition, 'garages'] = 0\n",
    "df_all.loc[condition, 'antiguedad'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df_all['metrostotales'].isnull()) & (df_all['tipodepropiedad'] == 'Terreno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso vemos que hay distribucion en las antiguedades distinta de 0. Esto podria tenerlo en cuenta \n",
    "# el algoritmo que usemos. Por lo que solo llenaremos los NULOS con 0 y no todos.\n",
    "df_all[condition].habitaciones.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizemos solo los nulos\n",
    "condition = (df_all['metrostotales'].isnull()) & (df_all['tipodepropiedad'] == 'Terreno')\n",
    "\n",
    "for col in ['antiguedad', 'habitaciones', 'banos', 'garages', 'metrostotales', 'gimnasio']:\n",
    "    df_all.loc[condition, col] = df_all[condition][col].fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_all[df_all['tipodepropiedad'] == 'Terreno'].corr()\n",
    "corr['precio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.metrostotales.isnull()].tipodepropiedad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos ahora apartamentos que tengan completado metrostotales y metroscubiertos. 80% poseen el mismo valor en ambos.\n",
    "notnull = (df_all['tipodepropiedad'] == 'Apartamento') & (~df_all['metrostotales'].isnull()) & (~df_all['metroscubiertos'].isnull())\n",
    "desigualmt2notnull = (df_all['tipodepropiedad'] == 'Apartamento') & (df_all['metrostotales'] != df_all['metroscubiertos']) & (~df_all['metrostotales'].isnull()) & (~df_all['metroscubiertos'].isnull())\n",
    "igualmt2notnull = (df_all['tipodepropiedad'] == 'Apartamento') & (df_all['metrostotales'] == df_all['metroscubiertos']) & (~df_all['metrostotales'].isnull()) & (~df_all['metroscubiertos'].isnull())\n",
    "null = (df_all['tipodepropiedad'] == 'Apartamento') & (df_all['metrostotales'].isnull() | df_all['metroscubiertos'].isnull())\n",
    "\n",
    "# import pandas.rpy.common as com\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# load the R package ISLR\n",
    "# infert = com.importr(\"ISLR\")\n",
    "\n",
    "# load the Auto dataset\n",
    "# auto_df = com.load_data('Auto')\n",
    "\n",
    "# calculate the correlation matrix\n",
    "corr = df_all[df_all['tipodepropiedad'] == 'Apartamento'].corr()\n",
    "corr['precio']\n",
    "# plot the heatmap\n",
    "# sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=\"YlGnBu\")\n",
    "# df_all[desigualmt2notnull].shape[0] / df_all[notnull].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos ahora apartamentos que tengan completado metrostotales y metroscubiertos.\n",
    "corr2 = df_all[igualmt2notnull].corr()\n",
    "(corr - corr2) > 0\n",
    "# sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=\"YlGnBu\")\n",
    "# df_all[igualmt2notnull].shape[0] / df_all[notnull].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.tipodepropiedad == 'Casa'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values(df_all[(df_all.tipodepropiedad == 'Casa')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolverCampo(tipodepropiedad, campo, test):\n",
    "    pred_train = df_all[(df_all.tipodepropiedad == tipodepropiedad) & (~df_all[campo].isnull())] \n",
    "    pred_test = df_all[(df_all.tipodepropiedad == tipodepropiedad) & (df_all[campo].isnull())]\n",
    "\n",
    "    every_column_except_y= [col for col in pred_train.columns if col not in [campo, 'id', 'ciudad', 'fecha', 'provincia', 'tipodepropiedad', 'precio', 'descripcion', 'titulo']]\n",
    "    \n",
    "    if(pred_train[every_column_except_y].shape[0] <= 1): return 0\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                    max_depth = 5, alpha = 10, n_estimators = 400, n_jobs=40)\n",
    "    \n",
    "    if(test): \n",
    "        X_train, X_test, y_train, y_test = train_test_split(pred_train[every_column_except_y], pred_train[campo], test_size=0.2, random_state=123)\n",
    "        xg_reg.fit(X_train,y_train)\n",
    "        pred= xg_reg.predict(X_test)     \n",
    "        return np.sqrt(mean_squared_error(y_test, pred))\n",
    "    else:    \n",
    "        xg_reg.fit(pred_train[every_column_except_y],pred_train[campo])\n",
    "        pred= xg_reg.predict(pred_test[every_column_except_y])\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['metrostotales'] = np.log1p(df_all['metrostotales'])\n",
    "df_all['metroscubiertos'] = np.log1p(df_all['metroscubiertos'])\n",
    "df_all['metrostotales'] = df_all['metrostotales'].fillna(0)\n",
    "df_all['metroscubiertos'] = df_all['metroscubiertos'].fillna(0)\n",
    "# for el in ['Apartamento','Casa', 'Casa en condominio', 'Local Comercial', 'Oficina comercial', 'Quinta Vacacional', 'Bodega comercial', 'Terreno comercial', 'Villa', 'Rancho', 'Edificio', 'Casa uso de suelo', 'Inmuebles productivos urbanos', 'Local en centro comercial', 'Departamento Compartido', 'Otros', 'Nave industrial', 'Duplex', 'Huerta', 'Terreno industrial', 'Garage', 'Hospedaje']:\n",
    "\n",
    "#     mtcubant = df_all.loc[(df_all.tipodepropiedad == el)].corr()['precio']['metroscubiertos']\n",
    "#     mtcubtot = df_all.loc[(df_all.tipodepropiedad == el)].corr()['precio']['metrostotales']\n",
    "    \n",
    "#     df_all.loc[(df_all.tipodepropiedad == el) & (df_all['metroscubiertos'].isnull()), 'metroscubiertos'] = resolverCampo(el, 'metroscubiertos', False)\n",
    "#     df_all.loc[(df_all.tipodepropiedad == el) & (df_all['metrostotales'].isnull()), 'metrostotales'] = resolverCampo(el, 'metrostotales', False)\n",
    "#     mtcubdes = df_all.loc[(df_all.tipodepropiedad == el)].corr()['precio']['metroscubiertos']\n",
    "#     mtcubdestot = df_all.loc[(df_all.tipodepropiedad == el)].corr()['precio']['metrostotales']\n",
    "\n",
    "# df_all['metrostotales'] = np.expm1(df_all['metrostotales'])\n",
    "# df_all['metroscubiertos'] = np.expm1(df_all['metroscubiertos'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[:, 'banos'] = df_all['banos'].fillna(0)\n",
    "df_all.loc[:, 'habitaciones'] = df_all['habitaciones'].fillna(0)\n",
    "df_all.loc[:, 'metroscubiertos'] = df_all['metroscubiertos'].fillna(0)\n",
    "df_all.loc[:, 'garages'] = df_all['garages'].fillna(0)\n",
    "df_all.loc[:, 'metrostotales'] = df_all['metrostotales'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import category_encoders as ce\n",
    "#Labeling\n",
    "\n",
    "cols = ['tipodepropiedad', 'provincia', 'ciudad'] \n",
    "         #, 'provincia', 'ciudad'\n",
    "        \n",
    "encoder = ce.BinaryEncoder(cols=cols)\n",
    "df_all = encoder.fit_transform(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[:train] = np.log(df_train.SalePrice)\n",
    "df_all['metros'] = np.abs(df_all['metroscubiertos'] + df_all['metrostotales'])\n",
    "df_all['preciomt2'] = df_all['precio'] / (df_all['metroscubiertos'] + df_all['metrostotales'])\n",
    "df_all['logpreciomt2'] = np.log1p(df_all.preciomt2)\n",
    "\n",
    "corr = df_all.corr().abs()\n",
    "corr.precio[corr.precio >= 0.5].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "#\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(df_all[:train.shape[0]].logpreciomt2, 25), percentile(df_all[:train.shape[0]].logpreciomt2, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "train = df_all[:train.shape[0]] \n",
    "test = df_all[train.shape[0]:] \n",
    "train = train[~((train.logpreciomt2 < lower) | (train.logpreciomt2 > upper) & (train.logpreciomt2 != 0))]\n",
    "df_all = train.append(test)\n",
    "\n",
    "\n",
    "# train.shape\n",
    "# outliers = [x for x in df_all[:train.shape[0]].logpreciomt2 if x < lower or x > upper]\n",
    "# print('Identified outliers: %d' % len(outliers))\n",
    "# outliers\n",
    "# outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "# print('Non-outlier observations: %d' % len(outliers_removed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train.metroscubiertos, train.logpreciomt2, c = \"blue\", marker = \"s\")\n",
    "plt.title(\"Metros vs logpreciomt2\")\n",
    "plt.xlabel(\"Metros\")\n",
    "plt.ylabel(\"logpreciomt2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "numeric_feats = df_all.dtypes[(df_all.dtypes == \"float64\") | (df_all.dtypes == \"int64\")].index\n",
    "skewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = [col for col in skewed_feats.index if col not in ['id', 'precio', 'preciomt2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = test[['id']]\n",
    "# final.loc[:, 'target'] = np.expm1(pred)\n",
    "train.set_index('id').to_csv('../normalized_train.csv')\n",
    "test.set_index('id').to_csv('../normalized_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
